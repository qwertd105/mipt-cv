# Домашнее задание 1: Тренировочный цикл и linear probe на ViT-Tiny

## Описание

В рамках этого задания проводится сравнение двух архитектур нейронных сетей для задачи классификации изображений:
- **CNN** — сверточная сеть, полностью обучаемая с нуля.
- **ViT-Tiny (linear probe)** — Vision Transformer, где энкодер заморожен, а обучается только линейная классификационная голова.

## Организация репозитория

```
hw1/
├── logs/
│   ├── cnn_main/ # логи обучения cnn
│   ├── cnn_sanity_check/ # логи sanity check cnn
│   ├── vit_main/ # логи обучения vit
│   ├── vit_sanity_check/ # логи sanity_check vit
├── cv_hw1.ipynb
├── README.md
└── requirements.txt
```

https://drive.google.com/drive/folders/11EzAu_wDBcHXVir-EKd6S2OI_hYae68Y?usp=sharing - images and traces

## Установка и запуск

- Открыть `cv_hw1.ipynb` в Google Colab.
- В меню **Runtime → Change runtime type** выбрать **GPU**.
- Установить зависимости запуском:
  ```
  !pip install -r requirements.txt
  ```
- Запустить ячейки по порядку.

## Подготовка данных

- Используется CIFAR-10 (10 классов, формат ImageFolder).
- Аугментации: `RandomResizedCrop(32)`, `RandomHorizontalFlip()`, специфичная нормализация.

## Обучение моделей

- Осуществлена sanity-check (accuracy=1 на 3 батчах), что подтверждает корректность данных и моделей.
- Трассировка первых 50 шагов.
- Весь процесс логируется в TensorBoard (loss, accuracy, lr, гистограммы весов/градиентов).

## Эксперимент 1: CNN

- ( conv2d -> bn -> relu -> max_pool ) * 3 -> Linear -> relu -> dropuot -> Linear
- На тесте: accuracy ~73%, macro F1 ~74%

## Эксперимент 2: ViT-Tiny (linear probe)

- Предобученный ViT-Tiny (vit_tiny_patch16_224), заморожены все слои, кроме финальной линейной головы на 10 классов.
- Использован CosineAnnealingLR для плавной адаптации learning rate.
- На тесте: accuracy ~81%, macro F1 ~81%  

## Сравнение моделей

- **Сходимость:** CNN достигает сходимости быстрее, но ViT с linear probe уже с первых эпох показывает более высокое качество благодаря использованию предобученного энкодера.
- **Обобщающая способность:** ViT демонстрирует лучший баланс между обучающей и валидационной выборками, минимальный gap train/val.
- **Ресурсы:** CNN требует меньше памяти и операций (32,402 против 71,956 у ViT — в 2.2 раза меньше).
- **Важные особенности:**
    - CNN чувствительна к lr и batch size, нуждается в регуляризации и аугментациях.
    - ViT-Tiny более ресурсоёмкая и медленная.

## Вывод

Эксперименты показали, что Vision Transformer с linear probe превосходит сверточную сеть по качеству классификации, даже на небольшом датасете с маленькими изображениями (32x32). Особенно заметно, что благодаря использованию предобученного энкодера, ViT показывает лучшие значения accuracy и F1 уже с первых эпох обучения — тогда как CNN приходится "учиться" с нуля. Однако, за это приходится платить существенно более высоким потреблением ресурсов и времени, что может быть критично в реальных применениях. Таким образом, выбор между CNN и ViT linear probe зависит от компромисса между качеством и вычислительными затратами, но благодаря претрейну ViT дает лучшие результаты сразу после начала обучения.